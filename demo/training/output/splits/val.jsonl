{"id": "frame_0030", "image": "/Users/mbp/Desktop/sam2_export_ca9924ef-6173-407c-af4d-07699588e9cc_extracted/sam2_export_ca9924ef-6173-407c-af4d-07699588e9cc/images/frame_000030.png", "conversations": [{"from": "human", "value": "<image>\nIdentify and segment all objects in this image."}, {"from": "gpt", "value": "I can see 1 s2, 1 S1, 1 a1 in the image with segmentation masks and bounding boxes."}], "masks": ["17067 1 254 2 254 2 253 3 252 3 253 3 252 4 252 4 251 5 251 5 250 6 250 7 249 7 248 8 248 8 247 9 247 10 246 10 245 11 245 12 244 12 243 14 242 14 242 15 240 16 240 17 239 18 238 19 236 22 1 1 232 25 231 25 231 24 231 24 232 23 233 22 234 21 235 20 235 20 236 20 236 19 237 18 238 17 238 17 239 16 240 15 241 14 242 13 242 13 243 12 244 11 244 11 245 10 246 9 247 8 248 8 248 7 249 6 249 5 251 5 251 3 33380", "23083 1 254 6 250 10 245 15 241 18 238 20 236 24 232 26 229 30 226 32 224 34 222 37 219 39 217 41 215 42 214 45 210 50 206 54 202 59 197 62 194 64 192 67 189 70 186 71 185 73 183 74 182 76 180 77 179 77 179 78 178 79 177 79 177 80 176 80 176 81 176 80 176 80 177 79 178 78 180 76 180 76 182 73 184 71 191 64 196 11 8 38 222 33 227 26 246 5 30359", "33675 4 251 6 249 10 246 12 244 14 243 16 241 16 242 15 242 15 242 14 243 14 243 13 244 12 244 12 245 11 246 10 247 9 248 7 249 7 251 3 26981"], "bounding_boxes": [[66, 153, 60, 31], [90, 39, 48, 81], [131, 137, 20, 21]], "frame_index": 30, "timestamp_sec": 1.0}
{"id": "frame_0048", "image": "/Users/mbp/Desktop/sam2_export_ca9924ef-6173-407c-af4d-07699588e9cc_extracted/sam2_export_ca9924ef-6173-407c-af4d-07699588e9cc/images/frame_000048.png", "conversations": [{"from": "human", "value": "<image>\nIdentify and segment all objects in this image."}, {"from": "gpt", "value": "I can see 1 s2, 1 S1, 1 a1 in the image with segmentation masks and bounding boxes."}], "masks": ["7344 1 254 2 254 2 253 3 253 2 253 3 253 4 251 5 251 5 250 6 250 6 249 7 249 7 249 8 247 9 247 9 247 10 245 11 245 11 244 13 243 13 243 14 242 14 241 16 240 17 239 17 238 19 237 21 235 22 234 27 228 27 229 26 230 26 230 25 230 25 231 25 231 24 232 24 232 23 232 23 233 22 234 22 234 21 235 20 235 21 235 20 236 19 237 18 238 18 237 18 238 17 239 16 240 15 241 15 241 14 241 14 242 13 243 13 242 13 243 13 243 12 243 12 244 11 244 12 244 11 244 11 245 11 244 11 245 10 246 9 247 8 248 8 249 6 251 3 39521", "22571 1 254 7 249 11 245 15 241 19 236 22 234 25 231 27 229 30 226 32 223 36 220 39 217 40 216 43 213 45 211 48 208 51 204 55 201 60 196 63 193 66 190 68 188 70 186 72 184 74 182 77 179 77 179 78 178 79 177 79 177 80 176 80 176 81 175 82 174 82 174 82 174 83 173 83 174 82 177 78 178 78 181 74 183 73 185 70 190 19 2 2 1 39 203 1 18 32 227 24 246 7 30870", "32139 5 250 9 246 11 245 14 241 16 241 18 239 19 237 20 237 20 237 20 237 19 240 16 242 14 243 13 244 13 244 11 246 10 247 9 248 7 250 6 251 4 254 1 28003"], "bounding_boxes": [[28, 154, 74, 38], [88, 39, 48, 83], [125, 136, 22, 25]], "frame_index": 48, "timestamp_sec": 1.6}
{"id": "frame_0084", "image": "/Users/mbp/Desktop/sam2_export_ca9924ef-6173-407c-af4d-07699588e9cc_extracted/sam2_export_ca9924ef-6173-407c-af4d-07699588e9cc/images/frame_000084.png", "conversations": [{"from": "human", "value": "<image>\nIdentify and segment all objects in this image."}, {"from": "gpt", "value": "I can see 1 s2, 1 S1, 1 a1 in the image with segmentation masks and bounding boxes."}], "masks": ["3249 2 254 2 253 3 253 3 252 3 253 3 253 3 252 5 251 5 250 6 250 6 249 7 249 7 249 8 247 9 247 9 246 10 246 11 245 11 244 12 244 13 243 13 243 14 241 15 241 15 19 1 221 16 17 2 220 18 16 2 220 19 14 2 221 19 13 2 222 20 12 2 221 22 10 2 222 23 8 3 222 25 5 3 223 32 223 32 224 31 225 31 225 30 225 30 226 30 226 29 227 28 228 28 227 28 228 27 229 26 230 26 230 25 230 25 231 25 231 24 232 23 233 23 233 22 233 22 234 21 235 21 235 20 236 19 236 19 237 19 237 18 238 17 239 16 240 15 240 16 240 15 241 15 241 14 241 14 242 14 242 13 242 13 243 13 242 13 243 12 243 13 243 12 243 13 243 12 243 12 244 11 245 10 246 9 247 8 248 7 250 6 250 4 40034", "27688 7 249 9 247 12 243 18 238 22 234 25 231 28 228 31 225 33 223 38 218 40 216 44 211 52 204 57 199 61 195 63 193 65 191 68 188 71 185 72 184 73 183 73 183 74 182 74 182 75 181 76 180 76 180 77 179 78 178 78 178 78 178 78 178 78 178 77 180 76 180 75 181 75 181 73 183 70 186 67 190 62 199 15 16 21 243 1 27051", "35720 2 250 9 246 11 244 13 243 15 241 17 240 17 240 18 239 18 239 19 238 19 239 17 240 17 241 15 242 15 242 14 243 13 244 12 245 10 247 9 248 8 249 6 251 5 252 4 23910"], "bounding_boxes": [[12, 153, 88, 50], [108, 38, 43, 78], [139, 130, 24, 26]], "frame_index": 84, "timestamp_sec": 2.8}
{"id": "frame_0036", "image": "/Users/mbp/Desktop/sam2_export_ca9924ef-6173-407c-af4d-07699588e9cc_extracted/sam2_export_ca9924ef-6173-407c-af4d-07699588e9cc/images/frame_000036.png", "conversations": [{"from": "human", "value": "<image>\nIdentify and segment all objects in this image."}, {"from": "gpt", "value": "I can see 1 s2, 1 S1, 1 a1 in the image with segmentation masks and bounding boxes."}], "masks": ["14512 1 254 2 254 2 254 2 253 3 252 4 252 4 251 5 250 6 250 6 249 7 249 7 248 8 248 9 247 9 246 10 246 10 246 11 244 12 244 12 244 13 242 14 242 15 241 15 240 17 239 18 238 18 237 21 235 22 234 24 232 26 229 27 229 26 230 25 231 24 231 25 231 24 232 23 233 22 234 21 234 21 235 20 236 20 236 19 237 18 237 18 238 17 239 16 240 15 240 15 241 14 242 14 241 14 242 13 242 13 243 12 243 13 242 13 243 12 243 12 244 11 245 10 246 9 247 8 249 6 250 4 34401", "24618 4 251 9 247 12 244 16 240 20 235 24 232 26 230 29 227 32 224 34 222 37 219 40 215 43 213 45 211 49 207 52 204 57 199 62 194 64 192 66 190 69 187 71 185 73 183 75 181 77 179 78 178 78 178 79 177 79 177 80 176 80 176 81 176 80 177 80 177 79 178 78 178 78 180 75 182 74 184 72 186 69 190 64 195 1 1 57 219 1 1 33 227 25 29587", "34187 1 253 7 247 12 244 13 244 14 243 15 242 17 240 17 240 17 241 15 242 15 242 14 243 14 243 13 244 12 245 11 246 10 247 9 248 7 250 6 251 4 253 3 25955"], "bounding_boxes": [[56, 154, 66, 36], [96, 39, 45, 82], [133, 135, 22, 24]], "frame_index": 36, "timestamp_sec": 1.2}
